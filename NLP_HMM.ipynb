{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "XXHMm6-BrDJf"
   },
   "outputs": [],
   "source": [
    "import nltk\n",
    "from nltk.corpus import brown\n",
    "import numpy as np\n",
    "from nltk.tag import map_tag\n",
    "from collections import defaultdict, Counter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "9PFobIbBvGQ7",
    "outputId": "1707e2d8-3212-465f-98fa-9abe13696fb5"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package brown to /root/nltk_data...\n",
      "[nltk_data]   Package brown is already up-to-date!\n",
      "[nltk_data] Downloading package universal_tagset to /root/nltk_data...\n",
      "[nltk_data]   Package universal_tagset is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "nltk.download('brown')\n",
    "nltk.download('universal_tagset')\n",
    "\n",
    "start_tag = '^'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "tzb-UM7a_2yd"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "lIeRys9FvOjR"
   },
   "outputs": [],
   "source": [
    "data = brown.tagged_sents(tagset='universal')\n",
    "# data = [(word.lower(),tag) for i in data for word, tag in i]\n",
    "# train_size = int(len(data) * 0.8)\n",
    "# train_data = data[:train_size]\n",
    "# test_data = data[train_size:]\n",
    "\n",
    "# train_data\n",
    "K = 5\n",
    "start = 0\n",
    "end = int(len(data)/K) -1\n",
    "\n",
    "emission_prob_list = []\n",
    "transition_prob_list = []\n",
    "\n",
    "data_fold_wise = []\n",
    "for i in range(K):\n",
    "  data_fold_wise.append(data[start:end])\n",
    "  start += int(len(data)/K)\n",
    "  end += int(len(data)/K)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "id": "TrkZca3N_41l"
   },
   "outputs": [],
   "source": [
    "tags = set(tag for sent in data for _, tag in sent)\n",
    "sorted_tags = sorted(tags)\n",
    "sorted_tags.append(start_tag)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "id": "wIFFQRMiljjh"
   },
   "outputs": [],
   "source": [
    "prt_words = set(_ for sent in data for _, tag in sent if tag == \"PRT\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "7KukvEcelype",
    "outputId": "b1193d5b-e0a4-4340-d4c5-5df471482d42"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{\"'ello\",\n",
       " \"'mon\",\n",
       " \"'tain't\",\n",
       " \"'tis\",\n",
       " 'Aaa-ee',\n",
       " 'Aaawww',\n",
       " 'Aah',\n",
       " 'Ah',\n",
       " 'Ah-ah',\n",
       " 'Ahah',\n",
       " 'Ahm',\n",
       " 'Alas',\n",
       " 'All',\n",
       " 'Amen',\n",
       " \"Arlene's\",\n",
       " \"Arthur's\",\n",
       " 'Atta',\n",
       " 'Aw',\n",
       " 'Aye-yah-ah-ah',\n",
       " 'Bah',\n",
       " \"Baseball's\",\n",
       " 'Be',\n",
       " \"Bill's\",\n",
       " \"Black's\",\n",
       " \"Blackwell's\",\n",
       " 'Bong',\n",
       " 'Boy',\n",
       " 'Bravo',\n",
       " \"Breed's\",\n",
       " \"Buckhorn's\",\n",
       " 'Bullshit',\n",
       " 'Bye',\n",
       " \"C'mon\",\n",
       " \"Celie's\",\n",
       " 'Chrissake',\n",
       " 'Christ',\n",
       " 'Creepers',\n",
       " \"Crosson's\",\n",
       " 'Crunch',\n",
       " 'Da-da-da-dum',\n",
       " 'Dammit',\n",
       " 'Down',\n",
       " 'Eh',\n",
       " \"Everything's\",\n",
       " 'Fiddlesticks',\n",
       " 'Gawdamighty',\n",
       " 'Gee',\n",
       " 'Glory',\n",
       " 'God',\n",
       " 'Goddammit',\n",
       " 'Goddamn',\n",
       " 'Golly',\n",
       " 'Good-by',\n",
       " 'Good-bye',\n",
       " 'Goodby',\n",
       " 'Goodbye',\n",
       " 'Goody',\n",
       " 'Goolick',\n",
       " 'Gosh',\n",
       " \"Great's\",\n",
       " \"Guardino's\",\n",
       " \"Gyp'll\",\n",
       " 'Half',\n",
       " 'Hallelujah',\n",
       " 'Harro',\n",
       " 'Haw',\n",
       " \"He'd\",\n",
       " \"He'll\",\n",
       " \"He's\",\n",
       " \"Heat's\",\n",
       " 'Heigh-ho',\n",
       " 'Hell',\n",
       " 'Hello',\n",
       " 'Henh',\n",
       " \"Here's\",\n",
       " 'Hey',\n",
       " 'Hi',\n",
       " 'Hmm',\n",
       " 'Hmpf',\n",
       " 'Hoa-whup',\n",
       " 'Hooray',\n",
       " \"How'd\",\n",
       " \"How's\",\n",
       " 'Howda',\n",
       " 'Howdy',\n",
       " 'Hubba',\n",
       " 'Hurrah',\n",
       " 'Hurray',\n",
       " 'Hush',\n",
       " \"I'd\",\n",
       " \"I'll\",\n",
       " \"I'm\",\n",
       " \"I've\",\n",
       " \"Ike's\",\n",
       " 'In',\n",
       " 'Indeed',\n",
       " \"It'll\",\n",
       " \"It's\",\n",
       " \"Jack's\",\n",
       " 'Jee-sus',\n",
       " 'Jeepers',\n",
       " 'Jerusalem',\n",
       " 'Jesus',\n",
       " \"John'll\",\n",
       " 'Jumping',\n",
       " 'Kaboom',\n",
       " \"Kate's\",\n",
       " \"Katharine's\",\n",
       " 'Kee-reist',\n",
       " 'Keeeerist',\n",
       " 'Keerist',\n",
       " \"Kitty's\",\n",
       " \"Knife's\",\n",
       " 'Krist',\n",
       " \"Lucille's\",\n",
       " 'M-m-m',\n",
       " \"Mack's\",\n",
       " \"Mahzeer's\",\n",
       " 'Man',\n",
       " 'Many',\n",
       " 'Mmm',\n",
       " 'Mmmm',\n",
       " 'Morning',\n",
       " 'My',\n",
       " \"Myra's\",\n",
       " \"Nobody's\",\n",
       " \"Nothing's\",\n",
       " 'O',\n",
       " 'O.K.',\n",
       " 'OK.',\n",
       " 'Off',\n",
       " 'Oh',\n",
       " 'Oh-the-pain-of-it',\n",
       " 'Okay',\n",
       " 'On',\n",
       " 'Oooo',\n",
       " 'Out',\n",
       " 'Over',\n",
       " \"Pa'd\",\n",
       " \"Pa's\",\n",
       " 'Pap-pap-pap-hey',\n",
       " \"Penny's\",\n",
       " \"Pietro's\",\n",
       " 'Please',\n",
       " 'Pugh',\n",
       " 'Quite',\n",
       " \"Rob's\",\n",
       " 'Rockabye',\n",
       " 'Roger',\n",
       " 'Say',\n",
       " \"Seaton's\",\n",
       " \"She'd\",\n",
       " \"She'll\",\n",
       " \"She's\",\n",
       " 'Shh',\n",
       " 'Shucks',\n",
       " \"Skolman's\",\n",
       " 'So',\n",
       " \"Somebody'll\",\n",
       " \"Somebody's\",\n",
       " \"Someone'll\",\n",
       " \"Someone's\",\n",
       " 'Sonuvabitch',\n",
       " \"Springfield's\",\n",
       " 'Sssshoo',\n",
       " 'Such',\n",
       " \"Summer's\",\n",
       " 'Sure-sure',\n",
       " \"That'll\",\n",
       " \"That's\",\n",
       " \"Them's\",\n",
       " 'There',\n",
       " \"There'd\",\n",
       " \"There'll\",\n",
       " \"There's\",\n",
       " \"They'd\",\n",
       " \"They'll\",\n",
       " \"They're\",\n",
       " \"They've\",\n",
       " \"Tim's\",\n",
       " 'To',\n",
       " 'Toot',\n",
       " 'Toot-toot',\n",
       " 'Ugh',\n",
       " 'Uh',\n",
       " 'Uh-huh',\n",
       " 'Uhhu',\n",
       " 'Um',\n",
       " 'Umm',\n",
       " 'Up',\n",
       " \"W.'s\",\n",
       " \"Wally's\",\n",
       " \"We'd\",\n",
       " \"We'll\",\n",
       " \"We're\",\n",
       " \"We've\",\n",
       " 'Welcome',\n",
       " 'Well',\n",
       " \"What'd\",\n",
       " \"What's\",\n",
       " 'Whee',\n",
       " \"Where'd\",\n",
       " \"Where're\",\n",
       " \"Where's\",\n",
       " \"Who'd\",\n",
       " \"Who'll\",\n",
       " \"Who's\",\n",
       " 'Whoa',\n",
       " 'Why',\n",
       " \"Why'n\",\n",
       " \"Whyn't\",\n",
       " 'Wow',\n",
       " \"Y're\",\n",
       " 'Yalagaloo',\n",
       " 'Yesiree',\n",
       " 'Yooee',\n",
       " \"You'd\",\n",
       " \"You'll\",\n",
       " \"You're\",\n",
       " \"You've\",\n",
       " 'Zingggg-O',\n",
       " 'a-gracious',\n",
       " 'about',\n",
       " 'across',\n",
       " 'after',\n",
       " 'ah',\n",
       " 'ahem',\n",
       " 'alas',\n",
       " 'all',\n",
       " 'amen',\n",
       " \"anybody'd\",\n",
       " 'ba-a-a',\n",
       " 'bang',\n",
       " 'bannnnnng',\n",
       " \"bastard's\",\n",
       " \"boat's\",\n",
       " 'boom-boom-boom',\n",
       " 'boy',\n",
       " 'buzz-buzz-buzz',\n",
       " \"camera's\",\n",
       " \"cane's\",\n",
       " \"company's\",\n",
       " \"cowhand'd\",\n",
       " 'crap',\n",
       " 'dairy-oh',\n",
       " 'dammit',\n",
       " 'damn',\n",
       " 'damnit',\n",
       " 'dear',\n",
       " 'diddle',\n",
       " \"doctor's\",\n",
       " 'doggone',\n",
       " 'down',\n",
       " \"duds'd\",\n",
       " 'eh',\n",
       " \"else's\",\n",
       " \"everything's\",\n",
       " 'farewell',\n",
       " \"fat's\",\n",
       " \"father's\",\n",
       " \"fire's\",\n",
       " 'godamit',\n",
       " 'goddamit',\n",
       " 'goddammit',\n",
       " 'golly',\n",
       " 'good-by',\n",
       " 'good-bye',\n",
       " 'good-night',\n",
       " 'goodbye',\n",
       " 'goodnight',\n",
       " 'goody',\n",
       " 'goooolick',\n",
       " 'gosh',\n",
       " \"granite's\",\n",
       " \"guy's\",\n",
       " 'ha',\n",
       " 'half',\n",
       " \"he'd\",\n",
       " \"he'll\",\n",
       " \"he's\",\n",
       " 'hell',\n",
       " \"hell's\",\n",
       " 'hello',\n",
       " 'help',\n",
       " \"here's\",\n",
       " 'hey',\n",
       " 'honest-to-Betsy',\n",
       " 'hoo-pig',\n",
       " \"how'd\",\n",
       " 'hubba',\n",
       " 'huh',\n",
       " 'huh-uh',\n",
       " 'hush',\n",
       " 'in',\n",
       " 'indeed',\n",
       " 'insomma',\n",
       " 'it',\n",
       " \"it'd\",\n",
       " \"it'll\",\n",
       " \"it's\",\n",
       " \"kid's\",\n",
       " \"kind's\",\n",
       " \"leg's\",\n",
       " \"level's\",\n",
       " 'lo',\n",
       " 'many',\n",
       " \"money's\",\n",
       " 'my',\n",
       " \"name's\",\n",
       " 'nary',\n",
       " \"nobody'd\",\n",
       " 'off',\n",
       " 'oh',\n",
       " 'okay',\n",
       " 'on',\n",
       " \"one's\",\n",
       " 'oops',\n",
       " \"other's\",\n",
       " 'out',\n",
       " \"out'n\",\n",
       " 'outta',\n",
       " 'over',\n",
       " \"oystchers'll\",\n",
       " 'pip',\n",
       " 'please',\n",
       " 'presto',\n",
       " 'pugh',\n",
       " 'quite',\n",
       " \"rain's\",\n",
       " 'rather',\n",
       " \"roulette's\",\n",
       " 'rum-tum-tum',\n",
       " 'sake',\n",
       " 'say',\n",
       " 'see',\n",
       " \"she'd\",\n",
       " \"she'll\",\n",
       " \"she's\",\n",
       " 'shucks',\n",
       " 'sir',\n",
       " \"sky's\",\n",
       " 'such',\n",
       " \"sun'll\",\n",
       " \"sun's\",\n",
       " 'sure-sure',\n",
       " \"t'\",\n",
       " \"t'jawn\",\n",
       " \"t'lah\",\n",
       " 'tarantara',\n",
       " \"that'd\",\n",
       " \"that's\",\n",
       " 'theare',\n",
       " 'ther',\n",
       " 'there',\n",
       " \"there'd\",\n",
       " \"there'll\",\n",
       " \"there's\",\n",
       " \"thet's\",\n",
       " \"they'd\",\n",
       " \"they'll\",\n",
       " \"they're\",\n",
       " \"they've\",\n",
       " \"this'll\",\n",
       " \"throat's\",\n",
       " 'through',\n",
       " 'to',\n",
       " \"today'll\",\n",
       " 'uh',\n",
       " 'uh-huh',\n",
       " 'uh-uh',\n",
       " 'uhhu',\n",
       " \"undersecretary's\",\n",
       " 'unnnt',\n",
       " 'up',\n",
       " 'up-pp',\n",
       " \"water's\",\n",
       " \"we'd\",\n",
       " \"we'll\",\n",
       " \"we're\",\n",
       " \"we've\",\n",
       " 'well',\n",
       " \"what're\",\n",
       " \"what's\",\n",
       " \"who'd\",\n",
       " \"who's\",\n",
       " 'whoosh',\n",
       " \"wife's\",\n",
       " \"y'know\",\n",
       " \"ye're\",\n",
       " \"you'd\",\n",
       " \"you'll\",\n",
       " \"you're\",\n",
       " \"you's\",\n",
       " \"you've\",\n",
       " 'zoooop',\n",
       " 'zounds'}"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prt_words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "LnzYo2--_9UU",
    "outputId": "cc8a02b1-fd6d-4a8c-8fa3-e15380d1b1a9"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['.',\n",
       " 'ADJ',\n",
       " 'ADP',\n",
       " 'ADV',\n",
       " 'CONJ',\n",
       " 'DET',\n",
       " 'NOUN',\n",
       " 'NUM',\n",
       " 'PRON',\n",
       " 'PRT',\n",
       " 'VERB',\n",
       " 'X',\n",
       " '^']"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sorted_tags"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "cuEecmisAA6c"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "id": "1V-QsAWfrHlh"
   },
   "outputs": [],
   "source": [
    "def calc_emission_prob(data):\n",
    "    word_tag_count = defaultdict(Counter)\n",
    "    tag_count = Counter()\n",
    "    emission_prob = defaultdict(dict)\n",
    "\n",
    "    for sentence in data:\n",
    "        for word, tag in sentence:\n",
    "            word_tag_count[word.lower()][tag] += 1\n",
    "            tag_count[tag] += 1\n",
    "\n",
    "    for word in word_tag_count:\n",
    "        for tag in word_tag_count[word]:\n",
    "          emission_prob[word][tag] = (word_tag_count[word][tag] + 1) / (tag_count[tag] + len(word_tag_count))\n",
    "\n",
    "          # if tag == \"NUM\" and (is_written_number(word) or is_number(word)):\n",
    "          #   emission_prob[word][tag] = (word_tag_count[word][tag] + tag_count[tag]*0.8) / (tag_count[tag] + len(word_tag_count))\n",
    "          # elif tag == \".\" and (re.search(r'[a-zA-Z]',word)):\n",
    "          #   emission_prob[word][tag] = (word_tag_count[word][tag] - tag_count[tag]*0.79) / (tag_count[tag] + len(word_tag_count))\n",
    "          # elif tag == \"NOUN\" and (re.search(r'ly$',word)):\n",
    "          #   emission_prob[word][tag] = (word_tag_count[word][tag] + tag_count[tag]*0.2) / (tag_count[tag] + len(word_tag_count))\n",
    "          # elif tag == \"NOUN\" and re.search(r'ness$',word):\n",
    "          #   emission_prob[word][tag] = (word_tag_count[word][tag] + tag_count[tag]*0.8) / (tag_count[tag] + len(word_tag_count))\n",
    "          # elif tag == \"ADV\" and (re.search(r'ly$',word)):\n",
    "          #   emission_prob[word][tag] = (word_tag_count[word][tag] + tag_count[tag]*0.79) / (tag_count[tag] + len(word_tag_count))\n",
    "          # # elif tag == \"PRT\" and ((re.search(r\"'d$\",word)) or re.search(r\"'s$\",word) or re.search(r\"'ll$\",word) or re.search(r\"^'\",word) or re.search(r\"'ve$\",word)):\n",
    "          # #   emission_prob[word][tag] = (word_tag_count[word][tag] + tag_count[tag]*0.79) / (tag_count[tag] + len(word_tag_count))\n",
    "          # # elif tag == \"PRT\" and (re.search(r\"[']\",word)):\n",
    "          # #   emission_prob[word][tag] = (word_tag_count[word][tag] + tag_count[tag]*0.2) / (tag_count[tag] + len(word_tag_count))\n",
    "          # else:\n",
    "          #   emission_prob[word][tag] = (word_tag_count[word][tag] + 1) / (tag_count[tag] + len(word_tag_count))\n",
    "\n",
    "    emission_prob_list.append(emission_prob)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "id": "wldP4KBrUbDp"
   },
   "outputs": [],
   "source": [
    "def calc_transition_prob(data):\n",
    "    tag_tag_count = defaultdict(Counter)\n",
    "    transition_prob = defaultdict(dict)\n",
    "    start_tag_count = Counter()\n",
    "    tag_count = Counter()\n",
    "\n",
    "    for sentence in data:\n",
    "        prev_tag = start_tag\n",
    "        for word, tag in sentence:\n",
    "            tag_tag_count[prev_tag][tag] += 1\n",
    "            prev_tag = tag\n",
    "            tag_count[tag] += 1\n",
    "\n",
    "    for prev_tag in tag_tag_count:\n",
    "        total_count = sum(tag_tag_count[prev_tag].values())\n",
    "        for curr_tag in tag_tag_count[prev_tag]:\n",
    "            transition_prob[prev_tag][curr_tag] = (tag_tag_count[prev_tag][curr_tag] + 1) / (total_count + len(tag_tag_count))\n",
    "\n",
    "    transition_prob_list.append(transition_prob)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "id": "dt0bC8wy9MRL"
   },
   "outputs": [],
   "source": [
    "import re\n",
    "\n",
    "def is_number(s):\n",
    "    if re.search(r'[$%]',s):\n",
    "      return False\n",
    "\n",
    "    # Check if the string contains at least one digit\n",
    "    if re.search(r'[0-9]', s):\n",
    "        if not re.search(r'[a-zA-Z]', s):\n",
    "          return True\n",
    "\n",
    "    return False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "id": "bwXbOoCkOQEX"
   },
   "outputs": [],
   "source": [
    "def is_written_number(s):\n",
    "    # Define a set of common written numbers\n",
    "    written_numbers = {\n",
    "        \"zero\", \"one\", \"two\", \"three\", \"four\", \"five\", \"six\", \"seven\", \"eight\", \"nine\", \"ten\",\n",
    "        \"eleven\", \"twelve\", \"thirteen\", \"fourteen\", \"fifteen\", \"sixteen\", \"seventeen\", \"eighteen\", \"nineteen\",\n",
    "        \"twenty\", \"thirty\", \"forty\", \"fifty\", \"sixty\", \"seventy\", \"eighty\", \"ninety\",\n",
    "        \"hundred\", \"thousand\", \"million\", \"billion\", \"trillion\", 'by', \"quintillion\",\"sextillion\",\"and\",\"to\",\"mid\",\n",
    "    }\n",
    "\n",
    "    # Handle compound numbers like \"twenty-one\"\n",
    "    s = s.lower().replace('-', ' ')\n",
    "    parts = s.split()\n",
    "\n",
    "    # Check if all parts are in the written numbers set\n",
    "    return all(part in written_numbers or is_number(part) for part in parts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "id": "3Ci86ecKW8Qn"
   },
   "outputs": [],
   "source": [
    "def viterbi_algo(sentence, fold_index):\n",
    "    sentence = sentence.copy()\n",
    "    sentence.append('.')\n",
    "    # if re.search(r'[a-zA-Z]',sentence[-1]):\n",
    "    #   sentence.append('.')\n",
    "    #   print(\"Sentence didn't ended with a .\")\n",
    "    viterbi_table = [{} for _ in range(len(sentence))]\n",
    "    backpointer = [{} for _ in range(len(sentence))]\n",
    "    emission_prob = emission_prob_list[fold_index]\n",
    "    transition_prob = transition_prob_list[fold_index]\n",
    "\n",
    "    for tag in transition_prob[start_tag]:\n",
    "        word = sentence[0].lower()\n",
    "        viterbi_table[0][tag] = transition_prob[start_tag].get(tag, 1e-6) * emission_prob.get(word, {}).get(tag, 1e-6)\n",
    "        backpointer[0][tag] = start_tag\n",
    "\n",
    "    for t in range(1, len(sentence)):\n",
    "        word = sentence[t].lower()\n",
    "        for curr_tag in transition_prob:\n",
    "            max_prob, best_prev_tag = max(\n",
    "                (viterbi_table[t-1][prev_tag] * transition_prob[prev_tag].get(curr_tag, 1e-6) * emission_prob.get(word, {}).get(curr_tag, 1e-6), prev_tag)\n",
    "                for prev_tag in viterbi_table[t-1]\n",
    "            )\n",
    "            viterbi_table[t][curr_tag] = max_prob\n",
    "            backpointer[t][curr_tag] = best_prev_tag\n",
    "\n",
    "    best_path = []\n",
    "    best_last_tag = max(viterbi_table[-1], key=viterbi_table[-1].get)\n",
    "    best_path.append(best_last_tag)\n",
    "    for t in range(len(sentence) - 1, 0, -1):\n",
    "        best_last_tag = backpointer[t][best_last_tag]\n",
    "        best_path.insert(0, best_last_tag)\n",
    "    best_path.pop()\n",
    "    return best_path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "id": "0gsp8j2G_dNK"
   },
   "outputs": [],
   "source": [
    "per_pos_accuracy = defaultdict(dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "id": "785BePIXAbXz"
   },
   "outputs": [],
   "source": [
    "for each_tag1 in sorted_tags:\n",
    "  for each_tag2 in sorted_tags:\n",
    "    per_pos_accuracy[each_tag1][each_tag2] = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "OO26IGAHAqO-",
    "outputId": "0d9aa6e2-7af7-422d-b005-3c3c6348c641"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "defaultdict(<class 'dict'>, {'.': {'.': 0, 'ADJ': 0, 'ADP': 0, 'ADV': 0, 'CONJ': 0, 'DET': 0, 'NOUN': 0, 'NUM': 0, 'PRON': 0, 'PRT': 0, 'VERB': 0, 'X': 0, '^': 0}, 'ADJ': {'.': 0, 'ADJ': 0, 'ADP': 0, 'ADV': 0, 'CONJ': 0, 'DET': 0, 'NOUN': 0, 'NUM': 0, 'PRON': 0, 'PRT': 0, 'VERB': 0, 'X': 0, '^': 0}, 'ADP': {'.': 0, 'ADJ': 0, 'ADP': 0, 'ADV': 0, 'CONJ': 0, 'DET': 0, 'NOUN': 0, 'NUM': 0, 'PRON': 0, 'PRT': 0, 'VERB': 0, 'X': 0, '^': 0}, 'ADV': {'.': 0, 'ADJ': 0, 'ADP': 0, 'ADV': 0, 'CONJ': 0, 'DET': 0, 'NOUN': 0, 'NUM': 0, 'PRON': 0, 'PRT': 0, 'VERB': 0, 'X': 0, '^': 0}, 'CONJ': {'.': 0, 'ADJ': 0, 'ADP': 0, 'ADV': 0, 'CONJ': 0, 'DET': 0, 'NOUN': 0, 'NUM': 0, 'PRON': 0, 'PRT': 0, 'VERB': 0, 'X': 0, '^': 0}, 'DET': {'.': 0, 'ADJ': 0, 'ADP': 0, 'ADV': 0, 'CONJ': 0, 'DET': 0, 'NOUN': 0, 'NUM': 0, 'PRON': 0, 'PRT': 0, 'VERB': 0, 'X': 0, '^': 0}, 'NOUN': {'.': 0, 'ADJ': 0, 'ADP': 0, 'ADV': 0, 'CONJ': 0, 'DET': 0, 'NOUN': 0, 'NUM': 0, 'PRON': 0, 'PRT': 0, 'VERB': 0, 'X': 0, '^': 0}, 'NUM': {'.': 0, 'ADJ': 0, 'ADP': 0, 'ADV': 0, 'CONJ': 0, 'DET': 0, 'NOUN': 0, 'NUM': 0, 'PRON': 0, 'PRT': 0, 'VERB': 0, 'X': 0, '^': 0}, 'PRON': {'.': 0, 'ADJ': 0, 'ADP': 0, 'ADV': 0, 'CONJ': 0, 'DET': 0, 'NOUN': 0, 'NUM': 0, 'PRON': 0, 'PRT': 0, 'VERB': 0, 'X': 0, '^': 0}, 'PRT': {'.': 0, 'ADJ': 0, 'ADP': 0, 'ADV': 0, 'CONJ': 0, 'DET': 0, 'NOUN': 0, 'NUM': 0, 'PRON': 0, 'PRT': 0, 'VERB': 0, 'X': 0, '^': 0}, 'VERB': {'.': 0, 'ADJ': 0, 'ADP': 0, 'ADV': 0, 'CONJ': 0, 'DET': 0, 'NOUN': 0, 'NUM': 0, 'PRON': 0, 'PRT': 0, 'VERB': 0, 'X': 0, '^': 0}, 'X': {'.': 0, 'ADJ': 0, 'ADP': 0, 'ADV': 0, 'CONJ': 0, 'DET': 0, 'NOUN': 0, 'NUM': 0, 'PRON': 0, 'PRT': 0, 'VERB': 0, 'X': 0, '^': 0}, '^': {'.': 0, 'ADJ': 0, 'ADP': 0, 'ADV': 0, 'CONJ': 0, 'DET': 0, 'NOUN': 0, 'NUM': 0, 'PRON': 0, 'PRT': 0, 'VERB': 0, 'X': 0, '^': 0}})\n"
     ]
    }
   ],
   "source": [
    "print(per_pos_accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "id": "o962Mztlg9Vf"
   },
   "outputs": [],
   "source": [
    "def calc_acc(actual, predicted):\n",
    "    correct = sum(1 for a, p in zip(actual, predicted) if a == p)\n",
    "    total = len(actual)\n",
    "    for a,p in zip(actual, predicted):\n",
    "      per_pos_accuracy[a][p] = per_pos_accuracy[a][p]+1\n",
    "    return (correct / total) * 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "5KbwNi8eOe3J",
    "outputId": "01071c05-7233-47d2-81e3-e8eb500f3b83"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold 1 :93.86117335953759\n",
      "Fold 2 :94.0681750371953\n",
      "Fold 3 :94.2546987774055\n",
      "Fold 4 :94.32776519277513\n",
      "Fold 5 :94.33253264409177\n",
      "Overall: 94.33253264409177\n"
     ]
    }
   ],
   "source": [
    "tag_predicted = []\n",
    "actual_tags = []\n",
    "\n",
    "for fold in range(K):\n",
    "    train_data = [data_fold_wise[i] for i in range(K) if i != fold]\n",
    "    train_data = [sentence for fold_data in train_data for sentence in fold_data]\n",
    "\n",
    "    calc_emission_prob(train_data)\n",
    "    calc_transition_prob(train_data)\n",
    "\n",
    "    for sentence in data_fold_wise[fold]:\n",
    "        input_words = [word for word, _ in sentence]\n",
    "        true_tags = [tag for _, tag in sentence]\n",
    "        best_tags = viterbi_algo(input_words, fold)\n",
    "\n",
    "        actual_tags.extend(true_tags)\n",
    "        tag_predicted.extend(best_tags)\n",
    "\n",
    "    accuracy = calc_acc(actual_tags, tag_predicted)\n",
    "    print(f\"Fold {fold + 1} :{accuracy}\")\n",
    "\n",
    "overall_accuracy = calc_acc(actual_tags, tag_predicted)\n",
    "print(f\"Overall: {overall_accuracy}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "id": "BGlfn2kXozoR",
    "outputId": "d5d22cbd-274a-45ad-b667-d6f4a6e13110"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\ns=[0,1,2]\\nprint(s[-1])\\nif re.search(r\\'[a-zA-Z]\\',\\'.kjjk\\'):\\n  print(\"True\")\\n'"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''\n",
    "s=[0,1,2]\n",
    "print(s[-1])\n",
    "if re.search(r'[a-zA-Z]','.kjjk'):\n",
    "  print(\"True\")\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "nRDIceHDBEeu",
    "outputId": "f82a27d7-3d12-4c67-fd96-38538b74f3fb"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\t.\tADJ\tADP\tADV\tCONJ\tDET\tNOUN\tNUM\tPRON\tPRT\tVERB\tX\t^\t\n",
      ".\t593596\t0\t4\t0\t0\t4\t8\t0\t0\t0\t0\t0\t493\t\n",
      "ADJ\t1317\t321223\t1260\t9441\t0\t7192\t15106\t18\t236\t263\t3160\t0\t228\t\n",
      "ADP\t98\t276\t593714\t7479\t610\t1791\t318\t5\t1096\t5615\t574\t0\t483\t\n",
      "ADV\t532\t9942\t8126\t201017\t305\t1324\t2403\t0\t363\t2406\t911\t0\t144\t\n",
      "CONJ\t6\t0\t78\t664\t156643\t432\t31\t0\t0\t0\t2\t0\t201\t\n",
      "DET\t5\t4\t2437\t184\t85\t566366\t34\t4\t3500\t6\t8\t0\t390\t\n",
      "NOUN\t18455\t20153\t8443\t700\t3\t17980\t1087309\t486\t9943\t484\t17675\t173\t933\t\n",
      "NUM\t817\t441\t367\t0\t0\t1900\t6033\t56117\t308\t3\t156\t0\t55\t\n",
      "PRON\t12\t4\t7050\t6\t0\t1448\t182\t0\t175266\t11\t34\t0\t67\t\n",
      "PRT\t45\t265\t13758\t1220\t0\t101\t1065\t0\t75\t100586\t190\t0\t80\t\n",
      "VERB\t1818\t5068\t4467\t371\t0\t5127\t31254\t0\t190\t22\t694953\t0\t537\t\n",
      "X\t453\t383\t445\t20\t16\t592\t2658\t15\t104\t13\t254\t814\t26\t\n",
      "^\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t\n"
     ]
    }
   ],
   "source": [
    "print('\\t',end=\"\")\n",
    "for tags in sorted_tags:\n",
    "  print(tags,end='\\t')\n",
    "print()\n",
    "for k1,p1 in per_pos_accuracy.items():\n",
    "  print(k1, end='\\t')\n",
    "  for k2,p2 in p1.items():\n",
    "    print(p2, end='\\t')\n",
    "  print()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Iuo3Iqdn7rOP"
   },
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "h-w6KIlO7s3M",
    "outputId": "d27da19c-99a7-4116-b562-1ea8d6c2c826"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(emission_prob_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "_EO_GxA4eZuC"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "7jj6B6K0CP4E",
    "outputId": "987124ea-79ce-4c85-afa0-4af9158e45e5"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['.',\n",
       " 'ADJ',\n",
       " 'ADP',\n",
       " 'ADV',\n",
       " 'CONJ',\n",
       " 'DET',\n",
       " 'NOUN',\n",
       " 'NUM',\n",
       " 'PRON',\n",
       " 'PRT',\n",
       " 'VERB',\n",
       " 'X',\n",
       " '^']"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sorted_tags"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "FGmDzRpwekQX",
    "outputId": "0ac5b8c4-3250-49f7-880d-e987854cc8a3"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\t.\tADJ\tADP\tADV\tCONJ\tDET\tNOUN\tNUM\tPRON\tPRT\tVERB\tX\t^\t\n",
      ".\t1.0\t0.0\t0.0\t0.0\t0.0\t0.0\t0.0\t0.0\t0.0\t0.0\t0.0\t0.0\t0.0\t\n",
      "ADJ\t0.0\t0.89\t0.0\t0.03\t0.0\t0.02\t0.04\t0.0\t0.0\t0.0\t0.01\t0.0\t0.0\t\n",
      "ADP\t0.0\t0.0\t0.97\t0.01\t0.0\t0.0\t0.0\t0.0\t0.0\t0.01\t0.0\t0.0\t0.0\t\n",
      "ADV\t0.0\t0.04\t0.04\t0.88\t0.0\t0.01\t0.01\t0.0\t0.0\t0.01\t0.0\t0.0\t0.0\t\n",
      "CONJ\t0.0\t0.0\t0.0\t0.0\t0.99\t0.0\t0.0\t0.0\t0.0\t0.0\t0.0\t0.0\t0.0\t\n",
      "DET\t0.0\t0.0\t0.0\t0.0\t0.0\t0.99\t0.0\t0.0\t0.01\t0.0\t0.0\t0.0\t0.0\t\n",
      "NOUN\t0.02\t0.02\t0.01\t0.0\t0.0\t0.02\t0.92\t0.0\t0.01\t0.0\t0.01\t0.0\t0.0\t\n",
      "NUM\t0.01\t0.01\t0.01\t0.0\t0.0\t0.03\t0.09\t0.85\t0.0\t0.0\t0.0\t0.0\t0.0\t\n",
      "PRON\t0.0\t0.0\t0.04\t0.0\t0.0\t0.01\t0.0\t0.0\t0.95\t0.0\t0.0\t0.0\t0.0\t\n",
      "PRT\t0.0\t0.0\t0.12\t0.01\t0.0\t0.0\t0.01\t0.0\t0.0\t0.86\t0.0\t0.0\t0.0\t\n",
      "VERB\t0.0\t0.01\t0.01\t0.0\t0.0\t0.01\t0.04\t0.0\t0.0\t0.0\t0.93\t0.0\t0.0\t\n",
      "X\t0.08\t0.07\t0.08\t0.0\t0.0\t0.1\t0.46\t0.0\t0.02\t0.0\t0.04\t0.14\t0.0\t\n"
     ]
    }
   ],
   "source": [
    "per_pos_precision = defaultdict(dict)\n",
    "for k1,p1 in per_pos_accuracy.items():\n",
    "  if k1 != '^':\n",
    "    i = 0\n",
    "    for k2,p2 in p1.items():\n",
    "      i += p2\n",
    "    for k2,p2 in p1.items():\n",
    "      per_pos_precision[k1][k2] = p2/i\n",
    "print('\\t',end=\"\")\n",
    "for tags in sorted_tags:\n",
    "  print(tags,end='\\t')\n",
    "print()\n",
    "for k1,p1 in per_pos_precision.items():\n",
    "  print(k1, end='\\t')\n",
    "  for k2,p2 in p1.items():\n",
    "    print(round(p2,2), end='\\t')\n",
    "  print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "NA2Wcm4gjTUv",
    "outputId": "93ccefbb-a0d7-4981-e9f0-71b617925b19"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['PRON', 'VERB', 'ADP', 'NOUN']"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "viterbi_algo(['I','live','in','Mumbai'],1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "id": "4GHF-WCRldyC"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "57340"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "9drl8UWg_bPJ",
    "outputId": "b862fc51-b742-4fe8-9e26-3dbfa33cddc1"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'PRON': 0.054311108981576865,\n",
       " 'NOUN': 3.185930929017459e-05,\n",
       " 'X': 4.60182692528934e-05}"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "emission_prob_list[0]['i']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "id": "hGMz1VBF_w8r"
   },
   "outputs": [],
   "source": [
    "import json\n",
    "# Convert to JSON\n",
    "json_data = json.dumps(emission_prob_list, indent=4)\n",
    "\n",
    "# Save to a file\n",
    "with open('emission_prob_list.json', 'w') as f:\n",
    "    f.write(json_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "id": "7zh2EXkrAYBU"
   },
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "# Load JSON from file\n",
    "with open('emission_prob_list.json', 'r') as f:\n",
    "    json_data = f.read()\n",
    "\n",
    "# Convert JSON to Python object\n",
    "emission_prob_list = json.loads(json_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "id": "yR0eZsHdAZz3"
   },
   "outputs": [],
   "source": [
    "import json\n",
    "# Convert to JSON\n",
    "json_data = json.dumps(transition_prob_list, indent=4)\n",
    "\n",
    "# Save to a file\n",
    "with open('transition_prob_list.json', 'w') as f:\n",
    "    f.write(json_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "_ZOpPfPcAtDF",
    "outputId": "ae8fd814-9925-4176-c02c-28474ab82de5"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.1298358797759421"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "transition_prob_list[0]['^'][\"NOUN\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "id": "92EcOI5GAqUS"
   },
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "# Load JSON from file\n",
    "with open('transition_prob_list.json', 'r') as f:\n",
    "    json_data = f.read()\n",
    "\n",
    "# Convert JSON to Python object\n",
    "transition_prob_list = json.loads(json_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "ZybvN8uBA6_U",
    "outputId": "4fc9d1a9-b66d-4e09-d448-b189010a13e5"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.1298358797759421"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "transition_prob_list[0]['^'][\"NOUN\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "LcGNICDzBJnK"
   },
   "source": [
    "Real Testing Code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "id": "oaqR8lyTBpoE"
   },
   "outputs": [],
   "source": [
    "def print_results(sentence, num_folds):\n",
    "    # Convert sentence to list of words\n",
    "    input_words = re.findall(r\"\\w+|[^\\w\\s]\", sentence)\n",
    "    # Dictionary to hold tags for each word position across all folds\n",
    "    tags_by_position = defaultdict(list)\n",
    "\n",
    "    # Collect POS tags from each fold\n",
    "    for fold in range(num_folds):\n",
    "        pos_tags = viterbi_algo(input_words, fold)\n",
    "\n",
    "        for position, tag in enumerate(pos_tags):\n",
    "            tags_by_position[position].append(tag)\n",
    "\n",
    "    # Determine the most probable tag for each position\n",
    "    most_probable_tags = []\n",
    "    for position in range(len(input_words)):\n",
    "        # Count the frequency of each tag at this position\n",
    "        tag_counts = Counter(tags_by_position[position])\n",
    "        # Get the most common tag\n",
    "        most_common_tag, _ = tag_counts.most_common(1)[0]\n",
    "        most_probable_tags.append(most_common_tag)\n",
    "\n",
    "    # Print results\n",
    "    for word, tag in zip(input_words, most_probable_tags):\n",
    "        print(f\"{word}: {tag}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "BOXeKIhfBLgP",
    "outputId": "ea22b263-ed5d-4301-e2bf-340275f1acf3"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "This: DET\n",
      "is: VERB\n",
      "the: DET\n",
      "course: NOUN\n",
      ".: .\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "import numpy as np\n",
    "from nltk.tag import map_tag\n",
    "from collections import defaultdict, Counter\n",
    "\n",
    "start_tag = '^'\n",
    "# Load JSON from file\n",
    "with open('emission_prob_list.json', 'r') as f:\n",
    "    json_data = f.read()\n",
    "\n",
    "# Convert JSON to Python object\n",
    "emission_prob_list = json.loads(json_data)\n",
    "num_folds = len(emission_prob_list)\n",
    "# Load JSON from file\n",
    "with open('transition_prob_list.json', 'r') as f:\n",
    "    json_data = f.read()\n",
    "\n",
    "# Convert JSON to Python object\n",
    "transition_prob_list = json.loads(json_data)\n",
    "sentence = \"This is the course.\"\n",
    "\n",
    "print_results(sentence,5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "FHMG9DYLDpQX",
    "outputId": "810e4b25-6b04-4122-da8c-821b27295e23"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5\n"
     ]
    }
   ],
   "source": [
    "print(num_folds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Qv0vfKvdG_vC",
    "outputId": "3fbef098-51cb-4a5d-a3e2-1c335886e88c"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "But: CONJ\n",
      ",: .\n",
      "soft: ADJ\n",
      "!: .\n",
      "what: DET\n",
      "light: NOUN\n",
      "through: ADP\n",
      "yonder: DET\n",
      "window: NOUN\n",
      "breaks: VERB\n",
      "?: .\n",
      "It: PRON\n",
      "is: VERB\n",
      "the: DET\n",
      "east: NOUN\n",
      ",: .\n",
      "and: CONJ\n",
      "Juliet: NOUN\n",
      "is: VERB\n",
      "the: DET\n",
      "sun: NOUN\n",
      ".: .\n"
     ]
    }
   ],
   "source": [
    "#To do  !!!! important\n",
    "sentence =\"But, soft! what light through yonder window breaks? It is the east, and Juliet is the sun.\"\n",
    "print_results(sentence,len(emission_prob_list))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
